{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.optimizers import SGD, adam\n",
    "import scipy.io as sio\n",
    "import loss.my_loss as my_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = {}\n",
    "training_set['received'] = sio.loadmat('.\\\\data\\\\denoise_set\\\\sps_4\\\\train_received')['received_set']\n",
    "training_set['clean'] = sio.loadmat('.\\\\data\\\\denoise_set\\\\sps_4\\\\train_clean')['clean_set']\n",
    "training_set['snr'] = sio.loadmat('.\\\\data\\\\denoise_set\\\\sps_4\\\\train_snr')['snr_set']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros([training_set['received'].shape[0],2,training_set['received'].shape[1]])\n",
    "x[:,0,:]=np.real(training_set['received'])\n",
    "x[:,1,:]=np.imag(training_set['received'])\n",
    "y = np.zeros([training_set['received'].shape[0],2,training_set['received'].shape[1]])\n",
    "y[:,0,:]=np.real(training_set['clean'])\n",
    "y[:,1,:]=np.imag(training_set['clean'])\n",
    "x = x.astype(np.float32)\n",
    "y = y.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "out_shape = list(x.shape)\n",
    "inp_shape = np.append(out_shape, 1)\n",
    "x = x.reshape(inp_shape)\n",
    "y = y.reshape(inp_shape)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard, EarlyStopping\n",
    "lr_decay = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, verbose=1, min_lr=1e-6, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=6, verbose=1, mode='min')\n",
    "callback_list = [lr_decay, early_stopping] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:75: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 4), padding=\"same\", kernel_initializer=\"he_normal\", activation=None, strides=(1, 1), name=\"input_layer\")`\n",
      "  name='input_layer', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_1_conv_1\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 4), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_1_conv_2\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_1_conv_3\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_2_conv_1\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 4), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_2_conv_2\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_2_conv_3\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_3_conv_1\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 4), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_3_conv_2\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_3_conv_3\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_4_conv_1\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 4), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_4_conv_2\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_4_conv_3\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_5_conv_1\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 4), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_5_conv_2\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_5_conv_3\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:91: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\", activation=None, strides=(1, 1), name=\"output_layer\")`\n",
      "  name='output_layer', padding='same', activation=None)(out)\n"
     ]
    }
   ],
   "source": [
    "import model.ddn as my_model\n",
    "model = my_model.resnet_buttleneck()\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss.my_loss import sqrt_evm_loss\n",
    "model.compile(loss=sqrt_evm_loss,\n",
    "                      optimizer='adam',\n",
    "                      metrics={'output_layer':sqrt_evm_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:18000]\n",
    "y_train = y[:18000]\n",
    "x_val = x[18000:]\n",
    "y_val = y[18000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "18000/18000 [==============================] - 86s - loss: 7.8996 - val_loss: 4.5950\n",
      "Epoch 2/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.8310 - val_loss: 2.9981\n",
      "Epoch 3/50\n",
      "18000/18000 [==============================] - 82s - loss: 3.3660 - val_loss: 2.9634\n",
      "Epoch 4/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2931 - val_loss: 2.9099\n",
      "Epoch 5/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2922 - val_loss: 2.8849\n",
      "Epoch 6/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2403 - val_loss: 2.8692\n",
      "Epoch 7/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2541 - val_loss: 2.8612\n",
      "Epoch 8/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2281 - val_loss: 2.8574\n",
      "Epoch 9/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2392 - val_loss: 2.8491\n",
      "Epoch 10/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2318 - val_loss: 2.8457\n",
      "Epoch 11/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2440 - val_loss: 2.8379\n",
      "Epoch 12/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2088 - val_loss: 2.8406\n",
      "Epoch 13/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2091 - val_loss: 2.8310\n",
      "Epoch 14/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.1702 - val_loss: 2.8200\n",
      "Epoch 15/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.1969 - val_loss: 2.8315\n",
      "Epoch 16/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.1914 - val_loss: 2.8182\n",
      "Epoch 17/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2112 - val_loss: 2.8183\n",
      "Epoch 18/50\n",
      "17984/18000 [============================>.] - ETA: 0s - loss: 3.2039\n",
      "Epoch 00017: reducing learning rate to 0.00020000000949949026.\n",
      "18000/18000 [==============================] - 81s - loss: 3.2037 - val_loss: 2.8196\n",
      "Epoch 19/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.2080 - val_loss: 2.8155\n",
      "Epoch 20/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.1718 - val_loss: 2.8245\n",
      "Epoch 21/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.1518 - val_loss: 2.8267\n",
      "Epoch 22/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.1587 - val_loss: 2.8145\n",
      "Epoch 23/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.1803 - val_loss: 2.8105\n",
      "Epoch 24/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.1897 - val_loss: 2.8289\n",
      "Epoch 25/50\n",
      "17984/18000 [============================>.] - ETA: 0s - loss: 3.1828\n",
      "Epoch 00024: reducing learning rate to 4.0000001899898055e-05.\n",
      "18000/18000 [==============================] - 81s - loss: 3.1826 - val_loss: 2.8111\n",
      "Epoch 26/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.1959 - val_loss: 2.8150\n",
      "Epoch 27/50\n",
      "18000/18000 [==============================] - 81s - loss: 3.1967 - val_loss: 2.8189\n",
      "Epoch 28/50\n",
      "17984/18000 [============================>.] - ETA: 0s - loss: 3.1952\n",
      "Epoch 00027: reducing learning rate to 8.000000525498762e-06.\n",
      "18000/18000 [==============================] - 81s - loss: 3.1955 - val_loss: 2.8149\n",
      "Epoch 00027: early stopping\n"
     ]
    }
   ],
   "source": [
    "history1 = model.fit(x=x_train, y=y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val,),\n",
    "                    callbacks=callback_list)\n",
    "model.save_weights('.\\\\weights\\\\ResNet_32_sqrtevmloss.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:75: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 4), padding=\"same\", kernel_initializer=\"he_normal\", activation=None, strides=(1, 1), name=\"input_layer\")`\n",
      "  name='input_layer', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_1_conv_1\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 4), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_1_conv_2\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_1_conv_3\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_2_conv_1\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 4), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_2_conv_2\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_2_conv_3\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_3_conv_1\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 4), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_3_conv_2\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_3_conv_3\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_4_conv_1\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 4), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_4_conv_2\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_4_conv_3\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_5_conv_1\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, padding=\"same\", kernel_size=(1, 4), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_5_conv_2\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:37: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, padding=\"same\", kernel_size=(1, 1), strides=(1, 1), kernel_initializer=\"he_normal\", activation=None, name=\"bblock_5_conv_3\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\ddn.py:91: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1, (1, 1), padding=\"same\", kernel_initializer=\"he_normal\", activation=None, strides=(1, 1), name=\"output_layer\")`\n",
      "  name='output_layer', padding='same', activation=None)(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/50\n",
      "18000/18000 [==============================] - 85s - loss: 294.0358 - val_loss: 108.5240\n",
      "Epoch 2/50\n",
      "18000/18000 [==============================] - 81s - loss: 50.0117 - val_loss: 20.3083\n",
      "Epoch 3/50\n",
      "18000/18000 [==============================] - 81s - loss: 22.1789 - val_loss: 14.3670\n",
      "Epoch 4/50\n",
      "18000/18000 [==============================] - 81s - loss: 21.4922 - val_loss: 14.1471\n",
      "Epoch 5/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.8624 - val_loss: 14.0106\n",
      "Epoch 6/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.2912 - val_loss: 13.7801\n",
      "Epoch 7/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.3217 - val_loss: 13.6900\n",
      "Epoch 8/50\n",
      "18000/18000 [==============================] - 80s - loss: 20.7158 - val_loss: 13.5889\n",
      "Epoch 9/50\n",
      "18000/18000 [==============================] - 81s - loss: 21.4155 - val_loss: 13.5241\n",
      "Epoch 10/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.1942 - val_loss: 13.5302\n",
      "Epoch 11/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.4257 - val_loss: 13.4791\n",
      "Epoch 12/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.0492 - val_loss: 13.4513\n",
      "Epoch 13/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.5801 - val_loss: 13.6273\n",
      "Epoch 14/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.5263 - val_loss: 13.4272\n",
      "Epoch 15/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.3697 - val_loss: 13.2814\n",
      "Epoch 16/50\n",
      "18000/18000 [==============================] - 81s - loss: 19.9580 - val_loss: 13.2845\n",
      "Epoch 17/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.0531 - val_loss: 13.2805\n",
      "Epoch 18/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.4386 - val_loss: 13.2245\n",
      "Epoch 19/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.2616 - val_loss: 13.2321\n",
      "Epoch 20/50\n",
      "17984/18000 [============================>.] - ETA: 0s - loss: 20.7191\n",
      "Epoch 00019: reducing learning rate to 0.00020000000949949026.\n",
      "18000/18000 [==============================] - 82s - loss: 20.7304 - val_loss: 13.3969\n",
      "Epoch 21/50\n",
      "18000/18000 [==============================] - 81s - loss: 19.8998 - val_loss: 13.1621\n",
      "Epoch 22/50\n",
      "18000/18000 [==============================] - 81s - loss: 19.3678 - val_loss: 13.3639\n",
      "Epoch 23/50\n",
      "18000/18000 [==============================] - 81s - loss: 19.9382 - val_loss: 13.1831\n",
      "Epoch 24/50\n",
      "18000/18000 [==============================] - 81s - loss: 20.1159 - val_loss: 13.2343\n",
      "Epoch 25/50\n",
      "18000/18000 [==============================] - 81s - loss: 19.9324 - val_loss: 13.1771\n",
      "Epoch 26/50\n",
      "17984/18000 [============================>.] - ETA: 0s - loss: 19.8635\n",
      "Epoch 00025: reducing learning rate to 4.0000001899898055e-05.\n",
      "18000/18000 [==============================] - 81s - loss: 19.8598 - val_loss: 13.1495\n",
      "Epoch 27/50\n",
      "18000/18000 [==============================] - 81s - loss: 19.6814 - val_loss: 13.1681\n",
      "Epoch 28/50\n",
      "18000/18000 [==============================] - 82s - loss: 20.3447 - val_loss: 13.1410\n",
      "Epoch 29/50\n",
      "17984/18000 [============================>.] - ETA: 0s - loss: 19.6635\n",
      "Epoch 00028: reducing learning rate to 8.000000525498762e-06.\n",
      "18000/18000 [==============================] - 82s - loss: 19.6718 - val_loss: 13.2182\n",
      "Epoch 00028: early stopping\n"
     ]
    }
   ],
   "source": [
    "import model.ddn as my_model\n",
    "model_3 = my_model.resnet_buttleneck()\n",
    "from loss.my_loss import evm_loss\n",
    "model_3.compile(loss=evm_loss,\n",
    "                      optimizer='adam',\n",
    "                      metrics={'output_layer':evm_loss})\n",
    "history3 = model_3.fit(x=x_train, y=y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=callback_list)\n",
    "model_3.save_weights('.\\\\weights\\\\ResNet_32_evmloss.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x190d4b81160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x190d4b81198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(history1.history['loss'], color='b', label=\"use evm\")\n",
    "ax.plot(history2.history['loss'], color='r', label=\"use log(evm)\")\n",
    "ax.plot(history3.history['loss'], color='y', label=\"use mse\")\n",
    "legend = ax.legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
