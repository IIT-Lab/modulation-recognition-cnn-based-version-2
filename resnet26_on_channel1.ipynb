{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard, EarlyStopping\n",
    "from model import classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 4), activation=None, name=\"s0\", kernel_initializer=\"he_normal\", padding=\"same\")`\n",
      "  out = Conv2D(64, (1,4), padding='same', init='he_normal', activation=None, name='s0')(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s1_block_1_conv_1\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s1_block_1_conv_2\", kernel_size=(1, 4), padding=\"same\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s1_block_1_conv_3\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s1_block_2_conv_1\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s1_block_2_conv_2\", kernel_size=(1, 4), padding=\"same\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s1_block_2_conv_3\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s2_block_1_conv_1\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s2_block_1_conv_2\", kernel_size=(1, 4), padding=\"same\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s2_block_1_conv_3\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s2_block_2_conv_1\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s2_block_2_conv_2\", kernel_size=(1, 4), padding=\"same\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s2_block_2_conv_3\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:93: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (2, 3), activation=None, name=\"s3\", kernel_initializer=\"he_normal\", padding=\"valid\")`\n",
      "  out = Conv2D(64, (2,3), padding='valid', init='he_normal', activation=None, name='s3')(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s4_block_1_conv_1\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s4_block_1_conv_2\", kernel_size=(1, 4), padding=\"same\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s4_block_1_conv_3\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s4_block_2_conv_1\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s4_block_2_conv_2\", kernel_size=(1, 4), padding=\"same\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s4_block_2_conv_3\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s5_block_1_conv_1\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s5_block_1_conv_2\", kernel_size=(1, 4), padding=\"same\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s5_block_1_conv_3\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s5_block_2_conv_1\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_1', padding='same', activation=None)(inp)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s5_block_2_conv_2\", kernel_size=(1, 4), padding=\"same\")`\n",
      "  name=name+'_conv_2', padding='same', activation=None)(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, None, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "s0 (Conv2D)                      (None, None, None, 64 320         input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, None, None, 64 256         s0[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, None, None, 64 0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "s1_block_1_conv_1 (Conv2D)       (None, None, None, 16 1040        activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, None, None, 16 64          s1_block_1_conv_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, None, None, 16 0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "s1_block_1_conv_2 (Conv2D)       (None, None, None, 16 1040        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, None, None, 16 64          s1_block_1_conv_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, None, None, 16 0           batch_normalization_3[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "s1_block_1_conv_3 (Conv2D)       (None, None, None, 64 1088        activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, None, None, 64 256         s1_block_1_conv_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, None, None, 64 0           batch_normalization_4[0][0]      \n",
      "                                                                   activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, None, None, 64 0           add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "s1_block_2_conv_1 (Conv2D)       (None, None, None, 16 1040        activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, None, None, 16 64          s1_block_2_conv_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, None, None, 16 0           batch_normalization_5[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "s1_block_2_conv_2 (Conv2D)       (None, None, None, 16 1040        activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, None, None, 16 64          s1_block_2_conv_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, None, None, 16 0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "s1_block_2_conv_3 (Conv2D)       (None, None, None, 64 1088        activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, None, None, 64 256         s1_block_2_conv_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, None, None, 64 0           batch_normalization_7[0][0]      \n",
      "                                                                   activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, None, None, 64 0           add_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)   (None, None, None, 64 0           activation_7[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "s2_block_1_conv_1 (Conv2D)       (None, None, None, 16 1040        max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, None, None, 16 64          s2_block_1_conv_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, None, None, 16 0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "s2_block_1_conv_2 (Conv2D)       (None, None, None, 16 1040        activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, None, None, 16 64          s2_block_1_conv_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, None, None, 16 0           batch_normalization_9[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "s2_block_1_conv_3 (Conv2D)       (None, None, None, 64 1088        activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNor (None, None, None, 64 256         s2_block_1_conv_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "add_3 (Add)                      (None, None, None, 64 0           batch_normalization_10[0][0]     \n",
      "                                                                   max_pooling2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, None, None, 64 0           add_3[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "s2_block_2_conv_1 (Conv2D)       (None, None, None, 16 1040        activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNor (None, None, None, 16 64          s2_block_2_conv_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, None, None, 16 0           batch_normalization_11[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "s2_block_2_conv_2 (Conv2D)       (None, None, None, 16 1040        activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNor (None, None, None, 16 64          s2_block_2_conv_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, None, None, 16 0           batch_normalization_12[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "s2_block_2_conv_3 (Conv2D)       (None, None, None, 64 1088        activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNor (None, None, None, 64 256         s2_block_2_conv_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "add_4 (Add)                      (None, None, None, 64 0           batch_normalization_13[0][0]     \n",
      "                                                                   activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, None, None, 64 0           add_4[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)   (None, None, None, 64 0           activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "s3 (Conv2D)                      (None, None, None, 64 24640       max_pooling2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNor (None, None, None, 64 256         s3[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, None, None, 64 0           batch_normalization_14[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)   (None, None, None, 64 0           activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "s4_block_1_conv_1 (Conv2D)       (None, None, None, 16 1040        max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNor (None, None, None, 16 64          s4_block_1_conv_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_15 (Activation)       (None, None, None, 16 0           batch_normalization_15[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "s4_block_1_conv_2 (Conv2D)       (None, None, None, 16 1040        activation_15[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNor (None, None, None, 16 64          s4_block_1_conv_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_16 (Activation)       (None, None, None, 16 0           batch_normalization_16[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "s4_block_1_conv_3 (Conv2D)       (None, None, None, 64 1088        activation_16[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNor (None, None, None, 64 256         s4_block_1_conv_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, None, None, 64 0           batch_normalization_17[0][0]     \n",
      "                                                                   max_pooling2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, None, None, 64 0           add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "s4_block_2_conv_1 (Conv2D)       (None, None, None, 16 1040        activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNor (None, None, None, 16 64          s4_block_2_conv_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, None, None, 16 0           batch_normalization_18[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "s4_block_2_conv_2 (Conv2D)       (None, None, None, 16 1040        activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNor (None, None, None, 16 64          s4_block_2_conv_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, None, None, 16 0           batch_normalization_19[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "s4_block_2_conv_3 (Conv2D)       (None, None, None, 64 1088        activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNor (None, None, None, 64 256         s4_block_2_conv_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "add_6 (Add)                      (None, None, None, 64 0           batch_normalization_20[0][0]     \n",
      "                                                                   activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, None, None, 64 0           add_6[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)   (None, None, None, 64 0           activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "s5_block_1_conv_1 (Conv2D)       (None, None, None, 16 1040        max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNor (None, None, None, 16 64          s5_block_1_conv_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, None, None, 16 0           batch_normalization_21[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "s5_block_1_conv_2 (Conv2D)       (None, None, None, 16 1040        activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNor (None, None, None, 16 64          s5_block_1_conv_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, None, None, 16 0           batch_normalization_22[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "s5_block_1_conv_3 (Conv2D)       (None, None, None, 64 1088        activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNor (None, None, None, 64 256         s5_block_1_conv_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "add_7 (Add)                      (None, None, None, 64 0           batch_normalization_23[0][0]     \n",
      "                                                                   max_pooling2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, None, None, 64 0           add_7[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "s5_block_2_conv_1 (Conv2D)       (None, None, None, 16 1040        activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNor (None, None, None, 16 64          s5_block_2_conv_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, None, None, 16 0           batch_normalization_24[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "s5_block_2_conv_2 (Conv2D)       (None, None, None, 16 1040        activation_24[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNor (None, None, None, 16 64          s5_block_2_conv_2[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "activation_25 (Activation)       (None, None, None, 16 0           batch_normalization_25[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "s5_block_2_conv_3 (Conv2D)       (None, None, None, 64 1088        activation_25[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNor (None, None, None, 64 256         s5_block_2_conv_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "add_8 (Add)                      (None, None, None, 64 0           batch_normalization_26[0][0]     \n",
      "                                                                   activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_26 (Activation)       (None, None, None, 64 0           add_8[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)   (None, None, None, 64 0           activation_26[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glob (None, 64)            0           max_pooling2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 10)            650         global_average_pooling2d_1[0][0] \n",
      "====================================================================================================\n",
      "Total params: 54,538\n",
      "Trainable params: 52,746\n",
      "Non-trainable params: 1,792\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:26: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, activation=None, strides=(1, 1), kernel_initializer=\"he_normal\", name=\"s5_block_2_conv_3\", kernel_size=(1, 1), padding=\"same\")`\n",
      "  name=name+'_conv_3', padding='same', activation=None)(out)\n",
      "D:\\python-wing-personal\\script\\MR_4\\model\\classifier.py:108: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n",
      "  out = Dense(cls_num, init='he_normal', activation='softmax', name='output')(out)\n"
     ]
    }
   ],
   "source": [
    "model = classifier.resnet_26()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = '.\\\\weights\\\\classifier\\\\resnet26_on_ch1_500k.h5'\n",
    "lr_decay = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, verbose=1, min_lr=1e-6)\n",
    "checkpointer = ModelCheckpoint(weight_path, verbose=1, save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min')\n",
    "callback_list = [lr_decay, checkpointer, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08),\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python35\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(epochs=100, steps_per_epoch=16000, validation_steps=300, max_queue_size=10, generator=<generator..., initial_epoch=0, use_multiprocessing=False, verbose=1, workers=1, class_weight=None, callbacks=[<keras.ca..., validation_data=<generator...)`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 1.0260 - acc: 0.5672Epoch 00000: val_loss improved from inf to 1.05208, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2988s - loss: 1.0260 - acc: 0.5672 - val_loss: 1.0521 - val_acc: 0.5866\n",
      "Epoch 2/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.9430 - acc: 0.6028Epoch 00001: val_loss did not improve\n",
      "16000/16000 [==============================] - 2979s - loss: 0.9430 - acc: 0.6028 - val_loss: 1.0825 - val_acc: 0.5849\n",
      "Epoch 3/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.9219 - acc: 0.6120Epoch 00002: val_loss improved from 1.05208 to 1.03498, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2975s - loss: 0.9219 - acc: 0.6121 - val_loss: 1.0350 - val_acc: 0.6026\n",
      "Epoch 4/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.9098 - acc: 0.6176Epoch 00003: val_loss improved from 1.03498 to 0.96548, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2968s - loss: 0.9098 - acc: 0.6177 - val_loss: 0.9655 - val_acc: 0.6151\n",
      "Epoch 5/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.9008 - acc: 0.6219Epoch 00004: val_loss did not improve\n",
      "16000/16000 [==============================] - 2965s - loss: 0.9008 - acc: 0.6219 - val_loss: 0.9801 - val_acc: 0.6099\n",
      "Epoch 6/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8946 - acc: 0.6244Epoch 00005: val_loss did not improve\n",
      "16000/16000 [==============================] - 2966s - loss: 0.8946 - acc: 0.6244 - val_loss: 0.9967 - val_acc: 0.6116\n",
      "Epoch 7/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8893 - acc: 0.6269Epoch 00006: val_loss improved from 0.96548 to 0.90825, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2994s - loss: 0.8893 - acc: 0.6269 - val_loss: 0.9083 - val_acc: 0.6251\n",
      "Epoch 8/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8848 - acc: 0.6286Epoch 00007: val_loss did not improve\n",
      "16000/16000 [==============================] - 2981s - loss: 0.8848 - acc: 0.6286 - val_loss: 0.9114 - val_acc: 0.6272\n",
      "Epoch 9/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8811 - acc: 0.6303Epoch 00008: val_loss improved from 0.90825 to 0.90800, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2990s - loss: 0.8811 - acc: 0.6303 - val_loss: 0.9080 - val_acc: 0.6254\n",
      "Epoch 10/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8778 - acc: 0.6320Epoch 00009: val_loss did not improve\n",
      "16000/16000 [==============================] - 2978s - loss: 0.8777 - acc: 0.6320 - val_loss: 0.9177 - val_acc: 0.6265\n",
      "Epoch 11/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8745 - acc: 0.6336Epoch 00010: val_loss did not improve\n",
      "16000/16000 [==============================] - 2965s - loss: 0.8745 - acc: 0.6336 - val_loss: 0.9096 - val_acc: 0.6261\n",
      "Epoch 12/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8719 - acc: 0.6346Epoch 00011: val_loss did not improve\n",
      "16000/16000 [==============================] - 2977s - loss: 0.8719 - acc: 0.6346 - val_loss: 0.9283 - val_acc: 0.6245\n",
      "Epoch 13/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8694 - acc: 0.6359Epoch 00012: val_loss improved from 0.90800 to 0.87869, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 3000s - loss: 0.8694 - acc: 0.6359 - val_loss: 0.8787 - val_acc: 0.6332\n",
      "Epoch 14/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8670 - acc: 0.6369Epoch 00013: val_loss did not improve\n",
      "16000/16000 [==============================] - 3055s - loss: 0.8670 - acc: 0.6369 - val_loss: 0.8862 - val_acc: 0.6319\n",
      "Epoch 15/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8651 - acc: 0.6378Epoch 00014: val_loss did not improve\n",
      "16000/16000 [==============================] - 2967s - loss: 0.8651 - acc: 0.6378 - val_loss: 0.8903 - val_acc: 0.6325\n",
      "Epoch 16/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8632 - acc: 0.6386Epoch 00015: val_loss improved from 0.87869 to 0.87364, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2968s - loss: 0.8632 - acc: 0.6386 - val_loss: 0.8736 - val_acc: 0.6332\n",
      "Epoch 17/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8617 - acc: 0.6391Epoch 00016: val_loss did not improve\n",
      "16000/16000 [==============================] - 2967s - loss: 0.8617 - acc: 0.6391 - val_loss: 0.8762 - val_acc: 0.6335\n",
      "Epoch 18/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8601 - acc: 0.6398Epoch 00017: val_loss did not improve\n",
      "16000/16000 [==============================] - 2967s - loss: 0.8601 - acc: 0.6398 - val_loss: 0.8877 - val_acc: 0.6323\n",
      "Epoch 19/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8584 - acc: 0.6406Epoch 00018: val_loss did not improve\n",
      "16000/16000 [==============================] - 2967s - loss: 0.8584 - acc: 0.6406 - val_loss: 0.8755 - val_acc: 0.6347\n",
      "Epoch 20/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8569 - acc: 0.6416Epoch 00019: val_loss did not improve\n",
      "16000/16000 [==============================] - 2967s - loss: 0.8569 - acc: 0.6416 - val_loss: 0.8846 - val_acc: 0.6327\n",
      "Epoch 21/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8558 - acc: 0.6421Epoch 00020: val_loss improved from 0.87364 to 0.87076, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2962s - loss: 0.8558 - acc: 0.6421 - val_loss: 0.8708 - val_acc: 0.6353\n",
      "Epoch 22/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8545 - acc: 0.6428Epoch 00021: val_loss improved from 0.87076 to 0.86176, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2959s - loss: 0.8545 - acc: 0.6428 - val_loss: 0.8618 - val_acc: 0.6402\n",
      "Epoch 23/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8534 - acc: 0.6433Epoch 00022: val_loss did not improve\n",
      "16000/16000 [==============================] - 2958s - loss: 0.8534 - acc: 0.6433 - val_loss: 0.8879 - val_acc: 0.6303\n",
      "Epoch 24/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8524 - acc: 0.6440Epoch 00023: val_loss did not improve\n",
      "16000/16000 [==============================] - 2958s - loss: 0.8524 - acc: 0.6440 - val_loss: 0.8665 - val_acc: 0.6332\n",
      "Epoch 25/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8512 - acc: 0.6442Epoch 00024: val_loss did not improve\n",
      "16000/16000 [==============================] - 2958s - loss: 0.8512 - acc: 0.6442 - val_loss: 0.8725 - val_acc: 0.6308\n",
      "Epoch 26/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8503 - acc: 0.6447Epoch 00025: val_loss did not improve\n",
      "16000/16000 [==============================] - 2958s - loss: 0.8503 - acc: 0.6447 - val_loss: 0.9021 - val_acc: 0.6297\n",
      "Epoch 27/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8494 - acc: 0.6450Epoch 00026: val_loss improved from 0.86176 to 0.86129, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2957s - loss: 0.8494 - acc: 0.6450 - val_loss: 0.8613 - val_acc: 0.6369\n",
      "Epoch 28/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8484 - acc: 0.6455Epoch 00027: val_loss did not improve\n",
      "16000/16000 [==============================] - 2957s - loss: 0.8484 - acc: 0.6455 - val_loss: 0.8802 - val_acc: 0.6304\n",
      "Epoch 29/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8477 - acc: 0.6459Epoch 00028: val_loss improved from 0.86129 to 0.85934, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2978s - loss: 0.8477 - acc: 0.6459 - val_loss: 0.8593 - val_acc: 0.6374\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8470 - acc: 0.6466Epoch 00029: val_loss did not improve\n",
      "16000/16000 [==============================] - 2981s - loss: 0.8470 - acc: 0.6466 - val_loss: 0.8740 - val_acc: 0.6370\n",
      "Epoch 31/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8461 - acc: 0.6467Epoch 00030: val_loss did not improve\n",
      "16000/16000 [==============================] - 2968s - loss: 0.8461 - acc: 0.6467 - val_loss: 0.8677 - val_acc: 0.6363\n",
      "Epoch 32/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8454 - acc: 0.6471Epoch 00031: val_loss did not improve\n",
      "16000/16000 [==============================] - 2980s - loss: 0.8454 - acc: 0.6471 - val_loss: 0.8683 - val_acc: 0.6359\n",
      "Epoch 33/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8446 - acc: 0.6473Epoch 00032: val_loss did not improve\n",
      "16000/16000 [==============================] - 2998s - loss: 0.8446 - acc: 0.6473 - val_loss: 0.8645 - val_acc: 0.6367\n",
      "Epoch 34/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8440 - acc: 0.6478\n",
      "Epoch 00033: reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 00033: val_loss did not improve\n",
      "16000/16000 [==============================] - 2959s - loss: 0.8440 - acc: 0.6478 - val_loss: 0.8691 - val_acc: 0.6370\n",
      "Epoch 35/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8269 - acc: 0.6543Epoch 00034: val_loss improved from 0.85934 to 0.85223, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2967s - loss: 0.8269 - acc: 0.6543 - val_loss: 0.8522 - val_acc: 0.6420\n",
      "Epoch 36/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8228 - acc: 0.6561Epoch 00035: val_loss improved from 0.85223 to 0.85200, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2978s - loss: 0.8228 - acc: 0.6561 - val_loss: 0.8520 - val_acc: 0.6420\n",
      "Epoch 37/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8211 - acc: 0.6569Epoch 00036: val_loss did not improve\n",
      "16000/16000 [==============================] - 2990s - loss: 0.8211 - acc: 0.6569 - val_loss: 0.8523 - val_acc: 0.6428\n",
      "Epoch 38/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8199 - acc: 0.6575Epoch 00037: val_loss did not improve\n",
      "16000/16000 [==============================] - 2995s - loss: 0.8199 - acc: 0.6575 - val_loss: 0.8524 - val_acc: 0.6428\n",
      "Epoch 39/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8189 - acc: 0.6580Epoch 00038: val_loss improved from 0.85200 to 0.85170, saving model to .\\weights\\classifier\\resnet26_on_ch1_500k.h5\n",
      "16000/16000 [==============================] - 2966s - loss: 0.8189 - acc: 0.6580 - val_loss: 0.8517 - val_acc: 0.6422\n",
      "Epoch 40/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8181 - acc: 0.6585Epoch 00039: val_loss did not improve\n",
      "16000/16000 [==============================] - 2958s - loss: 0.8181 - acc: 0.6585 - val_loss: 0.8522 - val_acc: 0.6430\n",
      "Epoch 41/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8174 - acc: 0.6591Epoch 00040: val_loss did not improve\n",
      "16000/16000 [==============================] - 2964s - loss: 0.8174 - acc: 0.6591 - val_loss: 0.8523 - val_acc: 0.6430\n",
      "Epoch 42/100\n",
      "15999/16000 [============================>.] - ETA: 0s - loss: 0.8167 - acc: 0.6595Epoch 00041: val_loss did not improve\n",
      "16000/16000 [==============================] - 2977s - loss: 0.8167 - acc: 0.6595 - val_loss: 0.8534 - val_acc: 0.6438\n",
      "Epoch 43/100\n",
      " 3600/16000 [=====>........................] - ETA: 2320s - loss: 0.8178 - acc: 0.6604"
     ]
    }
   ],
   "source": [
    "import tools as tool\n",
    "batch_num = 16000\n",
    "val_num = 300\n",
    "train_path = 'D:\\\\matlab2016b\\\\workplace\\\\signal_channel\\\\dataset\\\\recognize_set\\\\with_channel\\\\channel1\\\\batch_'\n",
    "val_path = 'D:\\\\matlab2016b\\\\workplace\\\\signal_channel\\\\dataset\\\\recognize_set\\\\with_channel\\\\channel1_val\\\\batch_'\n",
    "history = model.fit_generator(generator=tool.get_train_data(1, batch_num, train_path), steps_per_epoch=batch_num, epochs=100, verbose=1, \n",
    "                              callbacks=callback_list, validation_data=tool.get_val_data(1,val_num,val_path), validation_steps=val_num, \n",
    "                              class_weight=None, max_q_size=10, workers=1, pickle_safe=False, \n",
    "                              initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "test_num = 800\n",
    "y_hat = np.array([])\n",
    "y_true = np.array([])\n",
    "snr_list = np.array([])\n",
    "test_generator = tool.get_val_data(1, test_num, val_path)\n",
    "for i in range(1, test_num+1):\n",
    "    data = next(test_generator)\n",
    "    hat = model.predict(data[0], batch_size=64, verbose=1)\n",
    "    true = data[1]\n",
    "    hat = np.argmax(hat, axis=1)\n",
    "    true = np.argmax(true, axis=1)\n",
    "    y_hat = np.concatenate([y_hat, hat])\n",
    "    y_true = np.concatenate([y_true, true])\n",
    "    \n",
    "    snr = sio.loadmat(val_path+'snr'+str(i))['snrset']\n",
    "    snr = snr.reshape([-1,])\n",
    "    snr_list = np.concatenate([snr_list, snr], axis=0)\n",
    "print('over')\n",
    "print(y_hat.shape, y_true.shape)\n",
    "print(y_hat[1:10],y_true[1:10])\n",
    "print(snr_list[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs = [-18, -16, -14, -12, -10, -8, -6, -4, -2, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
    "acc_list = []\n",
    "for snr in snrs:\n",
    "    index = np.where(snr_list==snr)[0]\n",
    "    corr_count = len(np.where((y_hat[index]==y_true[index])==True)[0])\n",
    "    acc = corr_count / len(index)\n",
    "    print(acc)\n",
    "    acc_list.append(acc)\n",
    "plt.figure()\n",
    "plt.plot(snrs, acc_list, '.-b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas =  ['BPSK', 'QPSK', '8PSK', '16QAM', '64QAM', '128QAM', '2FSK', '4FSK', '8FSK', 'GMSK']\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, round(cm[i, j],4),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_mtx = confusion_matrix(y_true, y_hat)\n",
    "plot_confusion_matrix(confusion_mtx, clas, normalize=True, title='snr = -18dB:18dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_snr18 = np.where(snr_list==18)[0]\n",
    "confusion_mtx = confusion_matrix(y_true[index_snr18], y_hat[index_snr18])\n",
    "plot_confusion_matrix(confusion_mtx, clas, normalize=True, title='snr = 18dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_snr18 = np.where(snr_list==0)[0]\n",
    "confusion_mtx = confusion_matrix(y_true[index_snr18], y_hat[index_snr18])\n",
    "plot_confusion_matrix(confusion_mtx, clas, normalize=True, title='snr = 0dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
